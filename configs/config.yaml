train:
  batch_size: 64
  epochs: 5
  log_interval: 1100
  lr: 1e-4
  # for continuing training
  load_checkpoint: # change from None to ckeckpoint path
  more_epochs: 20 # How many more epochs to train

logger:
  checkpoint_path: "checkpoints/"
  chart_path: "tmp/"

system:
  device: "cuda:0"
  seed: 23

discriminator:
  input_channels: 1
  input_size: 250
  neurons: [64, 128, 256, 512]
  beta: 0.5

generator:
  nz: 64
  output_channels: 1
  output_size: 250
  neurons: [64, 128, 256, 512]
  beta: 0.5

run_date: ${now:%Y_%m_%d_%H_%M}
